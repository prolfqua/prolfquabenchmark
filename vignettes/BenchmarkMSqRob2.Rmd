---
title: "Benchmarking the msqrob2 package using the Ionstar Dataset starting from peptides.txt"
author: "FGCZ - (Draft)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      toc_collapsed: true
papersize: a4
geometry: margin=.5in
vignette: >
  %\VignetteIndexEntry{Benchmarking the proDA package using the Ionstar Dataset starting from peptides} 
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

```{r setup, include=TRUE} 
library(tidyverse)
library(limma)
library(QFeatures)
library(msqrob2)
library(plotly)
library(gridExtra)

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
evalAll <- require(proDA)
SAVE = TRUE

```


Here we benchmark the _msqrob2_ package using the `peptide.txt` intensities and median polish

We will be examining the `msqrobHurdle` method, which does produce inference using `rlm` from protein intensity estimates and uses `glm` to obtain estimates in those cases where no estimates are found. 


```{r fromPeptideTXT , eval = evalAll}
datadir <- file.path(find.package("prolfquadata") , "quantdata")
inputMQfile <-  file.path(datadir,
                          "MAXQuant_IonStar2018_PXD003881.zip")
inputAnnotation <- file.path(datadir, "annotation_Ionstar2018_PXD003881.xlsx")
mqdata <- list()
mqdata$data <- prolfqua::tidyMQ_Peptides(inputMQfile)
length(unique(mqdata$data$proteins))
mqdata$config <- prolfqua::create_config_MQ_peptide()

annotation <- readxl::read_xlsx(inputAnnotation)
res <- prolfqua::add_annotation(
  mqdata$data,
  annotation,
  fileName = "raw.file"
)

mqdata$config$table$factors[["dilution."]] = "sample"
mqdata$config$table$factors[["run_Id"]] = "run_ID"
mqdata$config$table$factorDepth <- 1
mqdata$data <- prolfqua::setup_analysis(res, mqdata$config)


lfqdata <- prolfqua::LFQData$new(mqdata$data, mqdata$config)
lfqdata$data <- lfqdata$data |> dplyr::filter(!grepl("^REV__|^CON__", protein_Id)) 
lfqdata$filter_proteins_by_peptide_count()
lfqdata$hierarchy_counts()

lfqdata$remove_small_intensities()
lfqdata$hierarchy_counts()

tr <- lfqdata$get_Transformer()
subset_h <- lfqdata$get_copy()
subset_h$data <- subset_h$data |> dplyr::filter(grepl("HUMAN", protein_Id))
subset_h <- subset_h$get_Transformer()$log2()$lfq
lfqdataNormalized <- tr$log2()$robscale_subset(lfqsubset = subset_h)$lfq

lfqAggMedpol <- lfqdataNormalized$get_Aggregator()
lfqAggMedpol$lmrob()
lfqtrans <- lfqAggMedpol$lfq_agg
st <- lfqtrans$get_Stats()
protAbundanceIngroup <- st$stats()
protAbundanceIngroup <- protAbundanceIngroup |> tidyr::pivot_wider(id_cols = protein_Id, names_from = dilution., names_prefix = "abd.", values_from = mean)


```


```{r aggregateMedianPolish, eval=TRUE, include = FALSE}


se <- prolfqua::LFQDataToSummarizedExperiment(lfqdata = lfqdataNormalized)
pe <- QFeatures::QFeatures(list(peptide = se), colData = colData(se))

my_medianPolish <- function(x, verbose = FALSE, ...){
  medpol <- stats::medpolish(x, na.rm = TRUE, trace.iter = verbose, maxiter = 10)
  return(medpol$overall + medpol$col)
}


pe <- QFeatures::aggregateFeatures(
  pe,
  i = "peptide", fcol = "protein_Id",
  name = "protein", fun = my_medianPolish, 
)
```

To use `proDA`, we need to create an `SummarizedExperiment`. We use the `to_wide` function of `prolfqua` to get the data in in the `SummarizedExperiment` compatible format.


## Defining Contrasts and computing group comparisons

As usual, two steps are required, first fit the models, then compute the contrasts.

```{r runMSRob, eval=evalAll, include=TRUE}
prlm <- msqrobHurdle(pe,
                     i = "protein",
                     formula = ~dilution.,
                     overwrite = TRUE)


getModel(rowData(prlm[["protein"]])$msqrobHurdleIntensity[[2]])
getModel(rowData(prlm[["protein"]])$msqrobHurdleCount[[2]])
```

Since msqrob does not report average abundances, we are computing them for each contrast.

```{r}

L <- makeContrast(c("dilution.e-dilution.d=0"),
                  parameterNames = c("dilution.e", "dilution.d"))
prlm <- hypothesisTestHurdle(prlm, i = "protein", L, overwrite = TRUE)
protAbundanceIngroup <- protAbundanceIngroup |> dplyr::mutate( avgAbd.e.d =  mean( c(abd.e,abd.d), na.rm = TRUE)  )

L <- makeContrast(c("dilution.d-dilution.c=0"),
                  parameterNames = c("dilution.d", "dilution.c"))
prlm <- hypothesisTestHurdle(prlm, i = "protein", L, overwrite=TRUE)
protAbundanceIngroup <- protAbundanceIngroup |> dplyr::mutate( avgAbd.d.c =  mean( c(abd.d,abd.c), na.rm = TRUE)  )


L <- makeContrast(c("dilution.c-dilution.b=0"),
                  parameterNames = c("dilution.c", "dilution.b"))
prlm <- hypothesisTestHurdle(prlm, i = "protein", L, overwrite = TRUE)
protAbundanceIngroup <- protAbundanceIngroup |> dplyr::mutate( avgAbd.c.b =  mean( c(abd.c,abd.b), na.rm = TRUE)  )

L <- makeContrast(c("dilution.b=0"),
                  parameterNames = c("dilution.b"))
prlm <- hypothesisTestHurdle(prlm, i = "protein", L, overwrite = TRUE)
protAbundanceIngroup <- protAbundanceIngroup |> dplyr::mutate( avgAbd.b.a =  mean( c(abd.b,abd.a), na.rm = TRUE)  )

xx <- rowData(prlm[["protein"]])
hurdle <- xx[grepl("hurdle_",names(xx))]

res <- list()
for (i in names(hurdle)) { 
  print(i)
  hurdle[[i]]$contrast <- i
  res[[i]] <- prolfqua::matrix_to_tibble(hurdle[[i]], preserve_row_names = "name")
}

hurdle <- dplyr::bind_rows(res)
nrow(hurdle)/4
hurdle$contrast |> unique()
hurdle |> filter(contrast == "hurdle_dilution.b")

```


Now we need to merge the results of both models msqrobHurdleIntensity and msqrobHurdleCount. To find out which models were not estimated by `msqrobHurdleIntensity` we check for NA's and use the `anti_join` to select those from the `msqrobHurdleCount` models.

```{r merge}
logFC <- hurdle |> dplyr::select("name","contrast", starts_with("logFC"))
logFC <- filter(logFC ,!is.na(logFCt))
logFC$modelName <- "msqrobHurdleIntensity"

logOR <- hurdle |> dplyr::select("name","contrast", starts_with("logOR"))
logOR$modelName <- "msqrobHurdleCount"

ddd <- dplyr::anti_join(logOR , logFC, by = c("name", "contrast"))
names(ddd) <- names(logFC)
all <- dplyr::bind_rows(ddd , logFC) |> dplyr::arrange(contrast, name)
names(all) <- c("name","contrast","logFC","se","df","t","pval","modelName")

all <- prolfqua::adjust_p_values(all, column = "pval", group_by_col = "contrast")
all$contrast |> unique()

all <- all |> dplyr::mutate(
  contrast = dplyr::case_when(
    contrast == "hurdle_dilution.b" ~ "dilution_(4.5/3)_1.5",
    contrast == "hurdle_dilution.c - dilution.b" ~ "dilution_(6/4.5)_1.3(3)",
    contrast == "hurdle_dilution.d - dilution.c" ~ "dilution_(7.5/6)_1.25",
    contrast == "hurdle_dilution.e - dilution.d" ~ "dilution_(9/7.5)_1.2",
    TRUE ~ "something wrong"))

protAbundanceIngroup <- protAbundanceIngroup |> 
  dplyr::select(-starts_with("abd")) |> 
  tidyr::pivot_longer(starts_with("avgAbd"), names_to = "contrast" ,values_to = "avgAbd")

protAbundanceIngroup <- protAbundanceIngroup |> 
  dplyr::mutate(contrast = dplyr::case_when(
  contrast == "avgAbd.b.a" ~ "dilution_(4.5/3)_1.5",
  contrast == "avgAbd.c.b" ~ "dilution_(6/4.5)_1.3(3)",
  contrast == "avgAbd.d.c" ~ "dilution_(7.5/6)_1.25",
  contrast == "avgAbd.e.d" ~ "dilution_(9/7.5)_1.2",
  TRUE ~ "something wrong"))

stopifnot(sum(all$contrast == "something wrong") == 0 )
stopifnot(sum(all$contrast == "something wrong") == 0 )



```


## Benchmarking

Here we use `proflqua` benchmark functions to generate some summaries.

```{r setUPBenchmark, eval = evalAll}
bb <- dplyr::inner_join(all, protAbundanceIngroup, by = c("name" = "protein_Id", "contrast" = "contrast"))
ttd <- prolfqua::ionstar_bench_preprocess( bb , idcol = "name" )
benchmark_msqrob <- prolfqua::make_benchmark(ttd$data,
                                             contrast = "contrast",
                                             toscale = c("pval"),
                                             fcestimate = "logFC",
                                             benchmark = list(
                                               list(score = "logFC", desc = TRUE),
                                               list(score = "t", desc = TRUE),
                                               list(score = "scaled.pval", desc = TRUE)
                                             ),  
                                             model_description = "msqrob_QFeature",
                                             model_name = "msqrob_QFeature",
                                             FDRvsFDP = list(list(score = "pval.adjusted", desc = FALSE))
                                             , hierarchy = c("name"), summarizeNA = "t"
)

sum(benchmark_msqrob$smc$summary$name)
sumarry <- benchmark_msqrob$smc$summary
prolfqua::table_facade(sumarry, caption = "nr of proteins with 0, 1, 2, 3 missing contrasts.")

```


```{r prepBenchmarkforComparison, include= FALSE, eval = evalAll}
xdd <- ttd$data |> dplyr::rename(protein_Id = name ,
                                 contrast = contrast,
                                 avgInt = avgAbd,
                                 diff = logFC,
                                 statistic = t,
                                 p.value = pval,
                                 FDR = pval.adjusted  
)
benchmark2_msqrob <- prolfqua::make_benchmark(xdd, model_description = "msqrob", model_name = "msqrob")
```

```{r eval=SAVE, include=FALSE}
saveRDS(benchmark2_msqrob, file = "../inst/Benchresults/benchmark_msqrob.RDS")

```

```{r rocCurve, fig.cap="ROC curves", eval = evalAll}
res <- benchmark_msqrob$pAUC_summaries()
knitr::kable(res$ftable$content,caption = res$ftable$caption)
res$barp
```

```{r pAUC02, fig.cap="plot ROC curves", eval = evalAll}
#res$ftable
benchmark_msqrob$plot_ROC(xlim = 0.2)
```

```{r fdrfdp, fig.cap = "plot FDR vs FDP",eval = evalAll}
benchmark_msqrob$plot_FDRvsFDP()
```

```{r fdptpr,eval = evalAll}
benchmark_msqrob$plot_FDPvsTPR()
```
