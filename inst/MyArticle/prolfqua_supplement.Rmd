---
title: "Supporting Information:\n prolfqua - A Comprehensive R-package for Proteomics Differential Expression Analysis"
author: 
  - name: Witold E. Wolski
    affiliation:
      - Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
      - Swiss Institute of Bioinformatics (SIB), Quartier Sorge - Batiment Amphipole, 1015 Lausanne, Switzerland
    email: wew@fgcz.ethz.ethz.ch
  - name: Paolo Nanni
    affiliation: Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
  - name: Jonas Grossmann
    affiliation:
      - Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
      - Swiss Institute of Bioinformatics (SIB), Quartier Sorge - Batiment Amphipole, 1015 Lausanne, Switzerland
  - name: Maria d'Errico
    affiliation:
      - Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
      - Swiss Institute of Bioinformatics (SIB), Quartier Sorge - Batiment Amphipole, 1015 Lausanne, Switzerland
  - name: Ralph Schlapbach
    affiliation: Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
  - name: Christian Panse
    affiliation:
      - Functional Genomics Center Zurich (FGCZ), ETH Zurich / University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland
      - Swiss Institute of Bioinformatics (SIB), Quartier Sorge - Batiment Amphipole, 1015 Lausanne, Switzerland
package: prolfqua
output:
  BiocStyle::pdf_document
abstract: |
  This document contains the supplements for the prolfqua manuscript available
  through \url{https://doi.org/10.1101/2022.06.07.494524}.
vignette: |
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
#bibliography: prolfqua.bib
---

\renewcommand{\thepage}{S--\arabic{page}}
\renewcommand{\tablename}{Supplementary Table}
\renewcommand{\figurename}{Supplementary Figure}

\newpage

```{r setup, include=FALSE}
Biocpkg <- function(pkg, label = NULL){
  url <- file.path("https://bioconductor.org/packages", pkg)
  BiocStyle:::labelled_link(pkg , label , url)
}

knitr::opts_chunk$set(echo = FALSE, error = FALSE, warning = FALSE, message = FALSE)
```

The sourcode used to produce this Document can be found in the  [prolfqua_supplement.Rmd](https://github.com/wolski/prolfquabenchmark/blob/main/inst/MyArticle/prolfqua_supplement.Rmd) file.

# How to install *prolfqua* and *prolfquabenchmark*

To install the *prolfqua* package ([ACS_JPR](https://github.com/fgcz/prolfqua/releases/tag/v0.4.3) release), including all R package dependencies, execute in the R console:

```{r installation, echo=TRUE, eval=FALSE}
remotes::install_github("https://github.com/fgcz/prolfqua/releases/tag/v0.4.5",
    dependencies = TRUE, build_vignettes=TRUE)
```

The R-markdown files with all the R code to run the benchmark for *prolfqua*, *msqrob2*, *MSStats* and *proDA* are available in the R package `r BiocStyle::Githubpkg('wolski/prolfquabenchmark')`. 

```{r installation2, echo=TRUE, eval=FALSE}
remotes::install_gitlab("wolski/prolfquadata", host="gitlab.bfabric.org")
remotes::install_github("https://github.com/wolski/prolfquabenchmark",
    dependencies = TRUE, build_vignettes=TRUE)
```

# DEA benchmark : IonStar/MaxQuant/peptide.txt - Significance test

Table \@ref(tab:ISMQpeptideSum) summarizes $pAUC$ of the DEA benchmark when using the IonStar/MaxQuant/peptide.txt data. Figure 5 in the Article, shows a barplot showing the $pAUC_{10}$.

We test if we should reject the null hypothesis that the area under the ROC curve at $0.1$ FDR ($pAUC_{10}$), computed using the scaled p-values (see scaled.p.value's in Table \@ref(tab:ISMQpeptideSum) ), do not differ for *msqrob2*, *proDA*, and `prolfqua_merged`. To this task we use the function `roc.test`, that performs a bootstrap method test for a difference in the pAUC of the ROC curves, from the R package `r BiocStyle::CRANpkg("pROC")`. The Table \@ref(tab:shwoROCtestREsultsIonStarMQ) shows the p-values of the pairwise bootstrap test for partial areas under the ROC curves.


```{r roctest, include = TRUE, eval = TRUE}
allBenchmarks <- readRDS("allBenchmarks.RDS")
ttmsqrob <- allBenchmarks$benchmark_msqrob$data()
ddmsqrob <- pROC::roc(ttmsqrob$TP, ttmsqrob$scaled.p.value, partial.auc = c(1, 0.9))

ttprolfqua <- allBenchmarks$benchmark_merged$data()
ddprolfqua <- pROC::roc(ttprolfqua$TP, ttprolfqua$scaled.p.value, partial.auc = c(1, 0.9))

ttproda <- allBenchmarks$benchmark_proDA$data()
ddproda <- pROC::roc(ttproda$TP, ttproda$scaled.p.value, partial.auc = c(1, 0.9))



tmp <- c(msqrob2_vs_prolfqua = pROC::roc.test(ddmsqrob,ddprolfqua, progress = "none")$p.value,
         msqrob2_vs_proda = pROC::roc.test(ddmsqrob,ddproda, progress = "none")$p.value,
         prolfqua_vs_proda = pROC::roc.test(ddprolfqua,ddproda, progress = "none")$p.value)

```

```{r ISMQpeptideSum}
mrob <- allBenchmarks$benchmark_msqrob$pAUC_summaries()$ftable$content
mrob$package <- "msqrob2"
proda <- allBenchmarks$benchmark_proDA$pAUC_summaries()$ftable$content
proda$package <- "proDA"
prolfqua <- allBenchmarks$benchmark_merged$pAUC_summaries()$ftable$content
prolfqua$package <- "prolfqua"
msstats <- allBenchmarks$benchmark_mssstats$pAUC_summaries()$ftable$content
msstats$package <- "MSstats"

ISMpeptide <- dplyr::bind_rows(mrob,proda,prolfqua, msstats) |> dplyr::filter(contrast == "all")
ISMpeptide$contrast <- NULL
ISMpeptide <-dplyr::relocate(ISMpeptide , package, .before="AUC") |> dplyr::arrange(what)
ISMpeptide$what[ISMpeptide$what=="statistic"] <- "t_statistic"
ISMpeptide |> 
  knitr::kable(digits = 1, caption = "Results of the DEA beanchmark for IonStar/MaxQuant/peptide.txt")
```


```{r shwoROCtestREsultsIonStarMQ}
cap = "p-values for pairwise comparsions of partial AUC at 0.1 for msqrob2, proDA and prolfqua for IonStar MaxQuant data."
knitr::kable(tibble::tibble(pROC_test = names(tmp), p.value = round(tmp, digits = 2)), format = "latex", caption = cap)

```

## Benchmark Vignettes

Pre-build version of the vignettes, we created to run the DEA benchmark, are available:

- [Benchmarking of methods implemented in prolfqua using the IonStar dataset MaxQuant](https://wolski.github.io/prolfquabenchmark/articles/BenchmarkingIonstarData.html) 
- [Benchmarking of MSstats using the IonStar dataset MaxQuant](https://wolski.github.io/prolfquabenchmark/articles/Benchmark_MSStats.html) 
- [Benchmarking of proDA  using the IonStar dataset MaxQuant](https://wolski.github.io/prolfquabenchmark/articles/Benchmark_proDA_medpolish.html) 
- [Benchmarking of msqrob2  using the IonStar dataset MaxQuant](https://wolski.github.io/prolfquabenchmark/articles/BenchmarkMSqRob2.html)  


# DEA benchmark : CPTAC/MaxQuant/peptide.txt

We applied DEA using *msqrob2*, *proDA* and *prolfqua*  to the CPTAC/MaxQuant dataset and benchmarked the results. We are using the `peptide.txt` file containing the peptide intensities.

The Rmarkdown file which generated these results, can be found here:
["DEA benchmark IonStar/FragPipeV14/combined_protein.tsv"](https://wolski.github.io/prolfquabenchmark/articles/Benchmark_cptac.html) 

```{r}
getpath <- function(filN){
    f1 <- paste0("../../inst/Benchresults/",filN)
    if (f1 == "") {
        f1 <- system.file("Benchresults",filN, package = "prolfquabenchmark")
    }
    message(f1)
    return(f1)
}
CPTACBenchmarks <- readRDS(getpath("CPTAC_Benchmark.RDS"))
mrob <- CPTACBenchmarks$benchmark_msqrob$pAUC_summaries()$ftable$content
mrob$package <- "msqrob2"
proda <- CPTACBenchmarks$benchmark_proDA$pAUC_summaries()$ftable$content
proda$package <- "proDA"
prolfqua <- CPTACBenchmarks$benchmark_merged$pAUC_summaries()$ftable$content
prolfqua$package <- "prolfqua"

all <- dplyr::bind_rows(list(mrob, proda, prolfqua))
all <- all |> 
  dplyr::filter(contrast == "b_vs_a")
all$what[all$what == "statistic"] <- "t_statistic"
all$what[all$what == "t"] <- "t_statistic"
all$what[all$what == "scaled.pval"] <- "scaled.p.value"
all$what[all$what == "logFC"] <- "diff"

all$contrast <- NULL
all |> dplyr::relocate(package, .before = "AUC") |> dplyr::arrange(what) |> 
  knitr::kable(digits = 1, caption = "Results of the DEA beanchmark for CPTAC/MaxQuant/peptide.txt")

```

Supplementary Figure \@ref(fig:plotCPTACbarplot) shows the partial area under the curve for *msqrob2*, *proDA* and *prolfqua*, when using the difference among the groups, the scaled p-values or the t-statistics to rank the proteins. For this dataset, the differences among groups show a higher performance than the t-statistic and scaled p-value. The *proDA* package performs slightly better then *prolfqua*  or *msqrob* although the differences are between the $pAUC_{10}$ for the scaled p-value score are not statistically significant. Table \@ref(tab:shwoROCtestREsultsCPTAC) shows the results of the Bootstrap test for two ROC curves. We observe that for this benchmark data, we can not reject the null hypothesis that there are no significant differences among the $pAUC_{10}$ (ROC based on scaled p-value) for the three packages. 

(ref:plotCPTACbarplot) Barplot showing the partial area under the ROC at 0.1 FDR for diff - differences among groups, scaled.p.value - $sign(diff) \cdot \textrm{p-value}$ and t-statistics. These results where obtained when using CPTAC/MaxQuant/peptide.txt as input.

```{r plotCPTACbarplot, fig.cap= "(ref:plotCPTACbarplot)"}

ggplot2::ggplot(all, ggplot2::aes(x = package, y = pAUC_10)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(~what)  + 
  ggplot2::theme_minimal() + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = -90, vjust = 0.5)) +
  ggplot2::xlab("")

```

```{r roctestCPTAC, include = TRUE, message=FALSE, error=FALSE}

ttmsqrob <- CPTACBenchmarks$benchmark_msqrob$data()
ddmsqrob <- pROC::roc(ttmsqrob$TP, ttmsqrob$scaled.pval, partial.auc = c(1, 0.9))
ttprolfqua <- CPTACBenchmarks$benchmark_merged$data()
ddprolfqua <- pROC::roc(ttprolfqua$TP, ttprolfqua$scaled.p.value, partial.auc = c(1, 0.9))
ttproda <- CPTACBenchmarks$benchmark_proDA$data()
ddproda <- pROC::roc(ttproda$TP, ttproda$scaled.pval, partial.auc = c(1, 0.9))


tmp <- c(msqrob2_vs_prolfqua = pROC::roc.test(ddmsqrob,ddprolfqua, progress = "none")$p.value,
         msqrob2_vs_proda = pROC::roc.test(ddmsqrob,ddproda, progress = "none")$p.value,
         prolfqua_vs_proda = pROC::roc.test(ddprolfqua,ddproda, progress = "none")$p.value)

```

Table \@ref(tab:shwoROCtestREsultsCPTAC) shows the results of the Bootstrap test for two ROC curves. 
We observe that for this benchmark data, we can not reject the null hypothesis that there are no significant differences among the $pAUC_{10}$ (ROC based on scaled p-value) for the three packages. 

```{r shwoROCtestREsultsCPTAC}
cap = "p-values for pairwise comparsions of partial AUC for msqrob2, proDA and prolfqua CPTAC/MaxQuant data."
knitr::kable(tibble::tibble(pROC_test = names(tmp), p.value = round(tmp, digits = 2)), format = "latex", caption = cap)

```

# DEA benchmark : IonStar/FragPipeV14/combined_protein.tsv

The Rmarkdown file which created these results, with more details about the IonStar FragPipe v14 dataset, and the data processing, can be found here:
["DEA benchmark IonStar/FragPipeV14/combined_protein.tsv"](https://wolski.github.io/prolfquabenchmark/articles/BenchmarkFragPipeProteinIonStar.html) 

After filtering for two peptides per protein the dataset comprises of $3836$ proteins.
Since we are using the combined_protein.tsv as input, comparison with neither *msqrob2* nor *MSstats* is possible. To fit the hurdle (*msqrob*) model, peptide intensities are required, while *MSstats* requires the `MSstats.tsv` file, containing precursor level abundances. However, starting from protein level intensities has the advantage that the effect size estimates obtained from the model agree with protein abundances, a feature frequently requested by the biologist.


```{r FragPipe}
FragPipeBenchmarks <- readRDS(getpath("FragPipev14_comb_prot.RDS"))
proda <- FragPipeBenchmarks$benchmark_proDA$pAUC_summaries()$ftable$content
proda$package <- "proDA"
prolfqua <- FragPipeBenchmarks$benchmark_prolfqua$pAUC_summaries()$ftable$content
prolfqua$package <- "prolfqua"


ISFPprot <- dplyr::bind_rows(proda, prolfqua)
ISFPprot$what[ISFPprot$what == "statistic"] <- "t_statistic"
ISFPprot$what[ISFPprot$what == "scaled.pval"] <- "scaled.p.value"
ISFPprot <- ISFPprot |> 
  dplyr::filter(contrast == "all")
ISFPprot$contrast <- NULL
ISFPprot |> dplyr::relocate(package, .before = "AUC") |> dplyr::arrange(what) |>
  knitr::kable(digits = 1, caption = "Results of the DEA beanchmark for IonStar/FragPipeV14/MSstats.tsv")

```

Supplementary Figure \@ref(fig:plotFragPipebarplot) shows the partial area under the curve for  *proDA* and *prolfqua*, computed by ranking the proteins using the difference among groups (diff), the scaled p-value (scaled.p.value) and the t-statistics (t_statistics),

(ref:plotFragPipebarplot) Barplot showing the partial area under the ROC at 0.1 FDR, for diff - difference among groups, scaled.p.value and t_statistic. These results where obtained when using FragPipeV14 combined_protein.txt as input.

```{r plotFragPipebarplot, fig.cap= "(ref:plotFragPipebarplot)"}

ggplot2::ggplot(ISFPprot, ggplot2::aes(x = package, y = pAUC_10)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(~what)  + 
  ggplot2::theme_minimal() + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = -90, vjust = 0.5)) +
  ggplot2::xlab("")

```

```{r roctestFRAGPIPE, include = TRUE, message=FALSE, error=FALSE}

ttprolfqua <- FragPipeBenchmarks$benchmark_prolfqua$data()
ddprolfqua <- pROC::roc(ttprolfqua$TP, ttprolfqua$scaled.p.value, partial.auc = c(1, 0.9))
ttproda <- FragPipeBenchmarks$benchmark_proDA$data()
ddproda <- pROC::roc(ttproda$TP, ttproda$scaled.pval, partial.auc = c(1, 0.9))

tmp <- c(prolfqua_vs_proda = pROC::roc.test(ddprolfqua,ddproda, progress = "none")$p.value)

```

Table \@ref(tab:shwoROCtestREsultsFRAGPIPE) shows the results of the Bootstrap test for the difference of two ROC curves. We observe that for this benchmark data, there are no significant differences among the $pAUC_{10}$ (for scaled p-value) for the two packages. 

```{r shwoROCtestREsultsFRAGPIPE}
cap = "p-values for pairwise comparsions of partial AUC for proDA and prolfqua CPTAC/MaxQuant data."
knitr::kable(tibble::tibble(pROC_test = names(tmp), p.value = round(tmp, digits = 2)), format = "latex", caption = cap)

```

# DEA benchmark : IonStar/FragPipeV14/MSstats.tsv

The Rmarkdown file which created these results, with more details about the analysis, can be found here:
["DEA benchmark IonStar/FragPipeV14/MSstats.tsv"](https://wolski.github.io/prolfquabenchmark/articles/BenchmarkFragPipeMSStats.Rmd) 

Since we are using the MSstats.tsv file containing precursor level abundances as input, we can benchmark the DEA performed of *msqrob2*, *MSstats*, *proflqua*, and *proda*. The dataset has 3899 proteins after filtering for two peptides per protein. Since we make four comparisons between groups, 15596 is the maximum possible number of effect size estimates. Supplementary Figure \@ref(fig:nrcomp) shows the number of comparisons obtained.
Supplementary Figure \@ref(fig:plotFragPipebarplot) shows the partial area under the curve for  *proDA* and *prolfqua*, computed by ranking the proteins using the difference among groups (diff), the scaled p-value (scaled.p.value) and the t-statistics (t_statistics),


```{r laodResutls, message=FALSE}
allB <- readRDS(getpath("FragPipev14_comb_MSStats.RDS"))
```

```{r nrcomp, fig.cap= "Number of comparisons for each method for IonStar/FragPipeV14/MSstats.tsv data."}
a1 <- allB$benchmark_proDA$smc$summary
names(a1)[2] <- "protein_Id"
a1$name <- allB$benchmark_proDA$model_name

a2 <- allB$benchmark_prolfqua$smc$summary
names(a2)[2] <- "protein_Id"
a2$name <- allB$benchmark_prolfqua$model_name

a3 <- allB$benchmark_msqrob$smc$summary
names(a3)[2] <- "protein_Id"
a3$name <- allB$benchmark_msqrob$model_name
a4 <- allB$benchmark_msstats$smc$summary
names(a4)[2] <- "protein_Id"
a4$name <- allB$benchmark_msstats$model_name
dd <- dplyr::bind_rows(list(a1,a2,a3,a4))
dd <- dd |> dplyr::mutate(nrcontrasts = protein_Id * (4 - nr_missing))
dds <- dd |> dplyr::group_by(name) |> dplyr::summarize(nrcontrasts = sum(nrcontrasts))
dds$percent <- dds$nrcontrasts/max(dds$nrcontrasts) * 100

nrgg <- dds |> ggplot2::ggplot(ggplot2::aes(x = name, y = nrcontrasts )) + 
  ggplot2::geom_bar(stat = "identity", fill = "white", colour = "black") + 
  ggplot2::coord_cartesian(ylim = c(min(dds$nrcontrasts) - 200, max(dds$nrcontrasts) + 10)) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = -90, vjust = 0.5)) +
  ggplot2::geom_text(
    ggplot2::aes(label = paste0(round(nrcontrasts, digits = 1),
                                paste0("  (",round(percent, digits = 1),"%)"))),
    vjust = 0, hjust = -0.2, angle = -90) #+ 
nrgg
```


(ref:isFPbarplot) 

```{r isFPbarplot, fig.cap="(ref:isFPbarplot)"}
proda <- allB$benchmark_proDA$pAUC_summaries()$ftable$content
proda$package <- "proDA"
prolfqua <- allB$benchmark_prolfqua$pAUC_summaries()$ftable$content
prolfqua$package <- "prolfqua"
msqrob2 <- allB$benchmark_msqrob$pAUC_summaries()$ftable$content
msqrob2$package <- "msqrob2"
tmp <- dplyr::bind_rows(proda, prolfqua, msqrob2)
bmsstats <- allB$benchmark_msstats$pAUC_summaries()$ftable$content
bmsstats$package <- "MSstats"
bmsstats$contrast <- bmsstats$Label
bmsstats$Label <- NULL
ISFPmsstats <- dplyr::bind_rows(list(proda, prolfqua, msqrob2, bmsstats))


ISFPmsstats$what[ISFPmsstats$what == "statistic"] <- "t_statistic"
ISFPmsstats$what[ISFPmsstats$what == "scaled.pval"] <- "scaled.p.value"
ISFPmsstats$what[ISFPmsstats$what == "scaled.pvalue"] <- "scaled.p.value"

ISFPmsstats$what[ISFPmsstats$what == "logFC"] <- "diff"
ISFPmsstats$what[ISFPmsstats$what == "log2FC"] <- "diff"
ISFPmsstats$what[ISFPmsstats$what == "t"] <- "t_statistic"
ISFPmsstats$what[ISFPmsstats$what == "Tvalue"] <- "t_statistic"
ISFPmsstats$what |> unique()

ISFPmsstats <- ISFPmsstats |> dplyr::filter(contrast == "all")
ISFPmsstats$contrast <- NULL
ISFPmsstats <- dplyr::relocate(ISFPmsstats, package, .before="AUC") |> dplyr::arrange(ISFPmsstats) 

ISFPmsstats |> 
  knitr::kable(digits = 1, caption = "Results of the DEA beanchmark for IonStar/FragPipeV14/MSstats.tsv")

ggplot2::ggplot(ISFPmsstats, ggplot2::aes(x = package, y = pAUC_10)) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::facet_wrap(~what)  + 
  ggplot2::theme_minimal() + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = -90, vjust = 0.5)) +
  ggplot2::xlab("")

```


# Comparing DEA results for MaxQuant and FragPipe

In the Article, we discussed other factors influencing the performance of the DEA analysis. One of these factors is the quantification software. Here we compare the benchmarking results obtained with MaxQuant and FragPipe. We see (Supplementary Figure \@ref(fig:compareMaxQuantFP)) that the choice of the signal processing software changes the partial area under the curve ($pAUC_{10}$) much stronger (by up to $8%$) than the DEA analysis method (by about 4%).
Furthermore, we observe that the DEA benchmark results differ depending on if _MSstats.tsv_ or _combined_protein.tsv_ is used as input. 

(ref:compareMaxQuantFP) Barplot, showing the DEA results ($pAUC_{10}$ - y axis) for four DEA methods and two signal processing methods (FragPipeV14/MSstats.tsv in black, FragPipeV14/combined_protein.txt dark gray and MaxQuant/peptide.txt in gray).


```{r compareMaxQuantFP, fig.cap="(ref:compareMaxQuantFP)"}
ISFPmsstats$software <- "FragPipe_precursor"
ISMpeptide$software <- "MaxQuant"
ISFPprot$software <- "FragPipe_protein"

tmp <- dplyr::bind_rows(list(ISFPmsstats, ISMpeptide,ISFPprot))

ggplot2::ggplot(tmp, aes(x=package, y = pAUC_10, fill = software))+
  ggplot2::geom_bar(stat = "identity",position = "dodge") +
  scale_fill_grey() +
  ggplot2::facet_wrap(~what)  + 
  ggplot2::theme_minimal() + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = -90, vjust = 0.5)) +
  ggplot2::xlab("")

```



# Estimating $A_{LOD}$

The main text describes how we estimate the abundance at the detection limit $A_{LOD}$. 
Supplementary Figure \@ref(fig:missignessHistogram) shows the distribution of the average abundance within a group for all proteins. The red density shows the distribution for those proteins without a missing value, and the olive, turquoise, and lilac density show for proteins with 1,2 and 3 missing values, respectively. We see that the proteins with three missing values have, on average lower abundances than those with no missing values. We are using the median of the proteins with a single observation per group; the lila density, as the $A_{LOD}$ estimate.

```{r missignessHistogram, fig.cap= "Distribution of the average abundance within group a and c for all proteins. Each density are color coded depending the number of missing observations per protein in a group.", echo=FALSE}

datadir <- file.path(find.package("prolfquadata") , "quantdata")
inputMQfile <-  file.path(datadir,
                          "MAXQuant_IonStar2018_PXD003881.zip")
inputAnnotation <- file.path(datadir, "annotation_Ionstar2018_PXD003881.xlsx")
mqdata <- list()

mqdata$data <- prolfqua::tidyMQ_Peptides(inputMQfile)
mqdata$config <- prolfqua::create_config_MQ_peptide()
annotation <- readxl::read_xlsx(inputAnnotation)
res <- prolfqua::add_annotation(
  mqdata$data,
  annotation,
  fileName = "raw.file"
)
mqdata$config$table$factors[["dilution."]] = "sample"
mqdata$config$table$factors[["run_Id"]] = "run_ID"
mqdata$config$table$factorDepth <- 1
mqdata$data <- prolfqua::setup_analysis(res, mqdata$config)
lfqdata <- prolfqua::LFQData$new(mqdata$data, mqdata$config)
lfqdata$data <- lfqdata$data |> 
  dplyr::filter(dilution. == "a" | dilution. =="c")
lfqdata$remove_small_intensities()
bb <- lfqdata$get_Plotter()
bb$missigness_histogram()
```

# The probabilities produced by ROPECA are not p-values

In the main text discuss that the properties of the Beta distribution-based probabilities, computed from peptide level p-values, using the ROPECA method are not well understood. 
We are running here a simulation experiment, which shows that if we start with a dataset where the null hypothesis is valid for all the peptides, i.e., the p-values are uniformly distributed, the produced Beta distribution-based probabilities are not uniformely distributed.

For all the peptides (`nrPep = 10000`) $H0$ is true. We know that if $H0$ is true, the distribution of the $p-values$ will be uniform. (Supplementary Figure \@ref(fig:figROPECA) left Panel). Therefore, we can omit the step of generating the data from $H0$ and computing the p-values but simulate the p-values directly by sampling from the uniform distribution (`runif(nrPep)`). 

By sampling 800 protein id's 10000 times (with replacement), we assign the peptides to proteins ('sample(1:800, size = nrPep,
   replace = TRUE, ...)'). To make the data more realistic, that is that some proteins have a lot of peptides, and many have just a few peptides; the density of sampling the protein Id is exponential (`dexp(seq(0,5,length = 800)`). Supplementary Figure \@ref(fig:figROPECA) center panel shows the number of proteins as a function of the number of peptides per protein. Afterward, we apply the ROPECA methods as discussed in the methods section of the manuscript. Supplementary Figure \@ref(fig:figROPECA) shows the distribution of the Beta distribution-based probabilities, which is not uniform. Hence, they do not have the same interpretation as p-values, i.e., the probability of falsely rejecting the $H0$ if $H0$ is true.
   

```{r figROPECA, fig.cap = "Left panel - distibution of peptide level p.values. Center panel - number of proteins as a function of the number of peptides per protein. Right panel - distribution of protein level p-values(?) obtained with the ropeca method."}
set.seed(10)
nrPep <- 10000
nrProtein <- 800
p.value <- runif(nrPep)
estimate <- rnorm(nrPep)
avgAbd <- runif(nrPep)
protein_Id <- sample(1:800, size = nrPep,
   replace = TRUE, prob = dexp(seq(0,5,length = 800)))

testdata <- data.frame(contrast = "contrast1",
   protein_Id = protein_Id,
   estimate = estimate,
   pseudo_estimate = estimate,
   p.value = p.value,
   avgAbd = avgAbd )

xx30 <- prolfqua::summary_ROPECA_median_p.scaled(testdata,
                                     subject_Id = "protein_Id",
                                     estimate = "estimate",
                                     p.value = "p.value",
                                     max.n = 30)

par(mfrow = c(1,3))
hist(testdata$p.value, breaks = 20, xlab = "p-value", main = "")
plot(table(table(protein_Id)), xlab = "nr of peptides/protein", ylab = "# nr of proteins", main = "")
hist(xx30$beta.based.significance, breaks = 20, xlab = "p-value(?) obtained with Ropeca.", main = "")

```

# Specifying Contrasts for Models with two Factors and Interaction Term

The following code illustrates how to specify a model with two factors and an interaction term and define the differences we want to estimate. The example dataset was acquired in two batches (p2370, p2691). In each, we measured Yeast samples grown under two different conditions (Glucose and Ethanol). This example is taken from the *prolfqua* package vignette file. To estimate treatment differences, we first specify the linear model that explains the observed protein abundances (transformedIntensities) using the explanatory variables `condition_` and `batch_` and the interaction term  `condition_:batch_`. Then, after fitting the model, we can estimate the treatment difference among the groups `Ethanol` and `Glucose` defined by the factor `condition` and similarly among the groups defined by `batch_`. Furthermore, we can examine differences between `Ethanol` and `Glucose` within each batch. We also can assess if these differences are the same or are different in both batches, i.e., if there is an interaction between condition and batch. We also show the code to compute the array of weights $c$ used to multiply the model coefficient $\beta$.

```{r contrast2, eval = TRUE, echo = TRUE}

Yeast2Factor <- prolfqua::prolfqua_data("data_Yeast2Factor")
Yeast2Factor$data |> dplyr::select(condition_, batch_) |> dplyr::distinct()
mlm <- prolfqua::strategy_lm(
  transformedIntensity ~ condition_ + batch_ + condition_:batch_
  )
mm <- prolfqua::build_model(Yeast2Factor$data, mlm, subject_Id = "protein_Id")

Contrasts <- c(
"diff_condition" = "condition_Ethanol - condition_Glucose",
"diff_batch" = "batch_p2370 - batch_p2691",
"diff_within_p2370" = 
  "`condition_Glucose:batch_p2370` - `condition_Ethanol:batch_p2691`",
"diff_within_p2691" = 
  "`condition_Glucose:batch_p2691` - `condition_Ethanol:batch_p2691`",
"diff_of_difference" = "diff_within_p2370 - diff_within_p2691")

linfct <- prolfqua::linfct_from_model(mm$modelDF$linear_model[[1]],
                                      as_list = FALSE)
mC <- prolfqua::linfct_matrix_contrasts(linfct, Contrasts)
## see Table 3 for content of mC
```

Table \@ref(tab:contrcoefficient) shows weights $c$ for each of the five contrasts we specified.

```{r contrcoefficient}
knitr::kable(mC, caption = "Weights $c$ for each of the contrasts (rows) which will be applied to the model parameter (columns).",format = "latex")
```

Given the weights $c$ contrasts from model parameters obtained with *proDA*, or *msqrob2* can be estimated, which will enables us to implement adapters to *proDA* or *msqrob2*.

For more details see *prolfqua* vignette: ["Modelling dataset with two Factors"](https://fgcz.github.io/prolfqua/articles/Modelling2Factors.html).


# Creating a prolfqua configuration

The following code demonstrates how we use *prolfqua* to analyze protein intensities reported in the MSFragger `combined_protein.tsv` file.
First, we create a tidy table containing the protein abundances by reading the `combined_protein.tsv` file using  `tidy_MSFragger_combined_protein.` Then, we read the sample annotation from the file `annotation.xlsx` file. Next, we create an `AnalysisTableAnnotation` R6 object.
Bottom-up proteomics data is hierarchical, i.e., a protein has peptides, peptides might be modified, etc. Therefore, the `AnalysisTableAnnotation` has a `hierarchy` field storing a list with an entry for each hierarchy level.
Since `combined_portein.tsv` only holds protein level data, the hierarchy list has one element, and we use it to specify which column contains the protein identifiers. We also need to define which column contains the protein abundances we want to use for the data analysis.
Finally, we have to specify which columns contain the explanatory variables of the analysis. The `AnalysisTableAnnotation` has the field `factors,` a list with as many entries as explanatory variables. Here we include two explanatory variables, the dilution, specified in the column 'sample', and 'run' stored in the column 'run_ID', representing the order of the measurement.


```{r echo=TRUE}
datadir <- file.path(find.package("prolfquadata") , "quantdata")
inputFragfile <-  file.path(datadir, "MSFragger_IonStar2018_PXD003881.zip")
inputAnnotation <- file.path(datadir, "annotation_Ionstar2018_PXD003881.xlsx")
# read input annotation
annotation <- readxl::read_xlsx(inputAnnotation)

protein <- tibble::as_tibble(
    read.csv(unz(inputFragfile,"IonstarWithMSFragger/combined_protein.tsv"),
             header = TRUE, sep = "\t", stringsAsFactors = FALSE))

# read combined_protein.tsv 
protein <- prolfqua::tidy_FragPipe_combined_protein_deprec(protein)
# remove proteins identified by a single peptide
protein <- protein |> 
  dplyr::filter(unique.stripped.peptides > 1)

# annotate the data
merged <- dplyr::inner_join(annotation, protein)
atable <- prolfqua::AnalysisTableAnnotation$new()
atable$fileName = "raw.file"
# specify column containing protein identifiers
atable$hierarchy[["protein_Id"]] = "protein"

# column with protein abundances
atable$set_response("total.intensity")

# the factors of the analysis
atable$factors[["dilution."]] = "sample"
atable$factors[["run"]] = "run_ID"

config <- prolfqua::AnalysisConfiguration$new(atable)

adata <- prolfqua::setup_analysis(merged, config)
lfqdata <- prolfqua::LFQData$new(adata, config)
# show number of proteins in the dataset
lfqdata$hierarchy_counts()

```


# Miscellaneous

(ref:tabCompletion) The screenshot displays the command-line completion (tab completion) of RStudio on the `prolfqua::LFQData` R6 object. In the example, it shows the getter methods of the object.

```{r tabCompletion, echo=FALSE, fig.cap="(ref:tabCompletion)", out.width = '66%'}
knitr::include_graphics("graphics/codeSnippet1TabCompletion.png")
```

```{r proLFQuaSticker, echo=TRUE, out.height="5cm", eval=TRUE, fig.cap="Sticker maintainer: Witold E. Wolski; License: Creative Commons Attribution CC-BY. Feel free to share and adapt, but don't forget to credit the author."}
file.path("graphics/hexStickerProlfqua.png") |>
  knitr::include_graphics()
```


# Session info {.unnumbered}

```{r sessionInfo, echo=FALSE}
pander::pander(sessionInfo())
```
